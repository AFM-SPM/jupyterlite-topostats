{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc681ed4-087e-45a1-9f55-91d23bcd42de",
   "metadata": {},
   "source": [
    "# TopoStats - Minicircle Walk-Through\n",
    "\n",
    "Welcome, this [Jupyter Notebook](https://jupyter.org/) will take you through processing `minicircle.spm` - a nanoscale AFM height image of DNA atop a flat mica surface using the Python package [TopoStats](https://afm-spm.github.io/TopoStats).\n",
    "\n",
    "Very little knowledge of [Python](https://www.python.org/) is assumed and attempts have been made to explain every step and where the user might change actions explain how to do so. But if something isn't clear please let us know by creating an [issue](https://github.com/AFM-SPM/jupyterlite-topostats/issues)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b595bc8-ac74-4182-8ff4-3a8df0a384c7",
   "metadata": {},
   "source": [
    "## Installing TopoStats\n",
    "\n",
    "By default the most recent stable release of TopoStats is installed in this JupyterLite Notebook. If however you wish to install the most recent development version directly from Git you should copy and paste the following into a new cell and execute it.\n",
    "\n",
    "```bash\n",
    "%pip install git+https://github.com/AFM-SPM/TopoStats.git@main\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67d027d-4fee-4dba-85e0-624d99850ed6",
   "metadata": {},
   "source": [
    "## Getting Started\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386691b8-2247-4895-b9b5-4bade440b7d9",
   "metadata": {},
   "source": [
    "## Install requirements\n",
    "\n",
    "A few libraries need manually loading  before you can run this Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367a5181-ab9e-45df-81b7-0ba00096d1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pgfinder==0.0.3\n",
    "%pip install ipywidgets matplotlib nupy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe935a6-591d-45fb-a65b-83087e320842",
   "metadata": {},
   "source": [
    "### Loading Libraries and Modules\n",
    "\n",
    "TopoStats is written as a series of modules with various classes and functions. In order to use these interactively we\n",
    "need to `import` them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec97eb28-ac26-449b-b419-fa89873e0ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from ipywidgets import widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from topostats.filters import Filters\n",
    "from topostats.grains import Grains\n",
    "from topostats.grainstats import GrainStats\n",
    "from topostats.io import find_files, read_yaml, write_yaml, LoadScans\n",
    "from topostats.logs.logs import setup_logger, LOGGER_NAME\n",
    "from topostats.plottingfuncs import Images\n",
    "from topostats.tracing.dnatracing import trace_image\n",
    "from topostats.utils import update_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126b15fe-6d2a-4b91-9465-9d374e0e2150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A composite widget for picking a file and displaying its name\n",
    "def named_file_upload(accept, description):\n",
    "    file_upload = widgets.FileUpload(accept=accept, description=description, multiple=False, layout=big_button)\n",
    "    file_name = widgets.Label(value=\"No file selected...\")\n",
    "\n",
    "    def handle_file_upload(file):\n",
    "        file_name.value = f\"Selected file : {file['new'][0]['name']}\"\n",
    "\n",
    "    file_upload.observe(handle_file_upload, names=\"value\")\n",
    "    return widgets.HBox([file_upload, file_name])\n",
    "\n",
    "# Layout for a bigger button\n",
    "big_button = widgets.Layout(width=\"auto\")\n",
    "\n",
    "# Style for wider description\n",
    "wide_style = {\"description_width\": \"initial\"}\n",
    "\n",
    "# Scan file upload\n",
    "scan_uploader = named_file_upload(\".spm,.gwy\", \"Upload Scan\")\n",
    "\n",
    "# Config file upload\n",
    "config_uploader = named_file_upload(\".yaml\", \"Upload Configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c078494-19e9-44a0-a06e-009c77420e9f",
   "metadata": {},
   "source": [
    "## Finding Files\n",
    "\n",
    "When run from the command line TopoStats needs to find files to process and the `find_files()` function helps here. It\n",
    "takes as an argument the directory path that should be searched and the file extension to look for (this example uses `.spm`\n",
    "files) and returns a list of all files in the specified directory which have that file extension\n",
    "directory. We can use that functionality in this Notebook if you place your files in the same directory as these\n",
    "Notebooks and execute the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d86aa8-453e-4e51-9493-a1f258eb16ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the base directory to be current working directory of the Notebook\n",
    "BASE_DIR = Path().cwd()\n",
    "# Alternatively if you know where your files area comment the above line and uncomment the below adjust it for your use.\n",
    "# BASE_DIR = Path(\"/path/to/where/my/files/are\")\n",
    "# Adjust the file extension approriately.\n",
    "FILE_EXT = \".spm\"\n",
    "# Search for *.spm files one directory level up from the current notebooks\n",
    "image_files = find_files(base_dir=BASE_DIR, file_ext=FILE_EXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0d8c1d-219b-4323-88ee-538e8b87127f",
   "metadata": {},
   "source": [
    "`image_files` is a list of images that match and we can look at that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03b7f00-2eff-480b-9fe9-43bbef4d6dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0f26df-5275-46e6-b309-f7533d6de21f",
   "metadata": {},
   "source": [
    "## Loading your own file\n",
    "\n",
    "A sample file, `minicircle.spm` is provided in the `data` directory of this Jupyter Lab page you loaded this Notebook from and that is loaded into the `image_files` list above using `find_files()`. If however you have your own scan you wish to process you can upload it using the button below.\n",
    "\n",
    "**NB** You _must_ execute the cell first for the button to appear and for the moment only `.spm` files are supported although TopoStats does support other formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddb7ccb-2a8d-4720-87e5-26a910496a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO - How to access the selected file as part of TopoStats?\n",
    "display(scan_uploader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9702d05e-31bd-4321-904f-af7642739c26",
   "metadata": {},
   "source": [
    "## Loading a Configuration\n",
    "\n",
    "You can specify all options explicitly by hand when instantiating classes or calling methods/functions. However when run\n",
    "at the command line in batch mode TopoStats loads these options from a [YAML](https://yaml.org/) configuration file and it is worth\n",
    "understanding the structure of this file and how it is used.\n",
    "\n",
    "A trimmed version is shown below. The words that come before the colon `:` are the option, e.g. `base_dir:` is the base\n",
    "directory that is searched for files, what comes after is the value, in this case `./tests/`\n",
    "\n",
    "\n",
    "```yaml\n",
    "base_dir: ./ # Directory in which to search for data files\n",
    "output_dir: ./output # Directory to output results to\n",
    "log_level: info # Verbosity of output. Options: warning, error, info, debug\n",
    "cores: 2 # Number of CPU cores to utilise for processing multiple files simultaneously.\n",
    "file_ext: .spm # File extension of the data files.\n",
    "loading:\n",
    "  channel: Height # Channel to pull data from in the data files.\n",
    "filter:\n",
    "  run: true # Options : true, false\n",
    "  row_alignment_quantile: 0.5 # below values may improve flattening of larger features\n",
    "  threshold_method: std_dev # Options : otsu, std_dev, absolute\n",
    "  otsu_threshold_multiplier: 1.0\n",
    "  threshold_std_dev:\n",
    "    below: 10.0 # Threshold for data below the image background\n",
    "    above: 1.0 # Threshold for data above the image background\n",
    "  threshold_absolute:\n",
    "    below: -1.0 # Threshold for data below the image background\n",
    "    above: 1.0 # Threshold for data above the image background\n",
    "  gaussian_size: 1.0121397464510862 # Gaussian blur intensity in px\n",
    "  gaussian_mode: nearest\n",
    "  # Scar remvoal parameters. Be careful with editing these as making the algorithm too sensitive may\n",
    "  # result in ruining legitimate data.\n",
    "  remove_scars:\n",
    "    run: true\n",
    "    removal_iterations: 2 # Number of times to run scar removal.\n",
    "    threshold_low: 0.250 # below values make scar removal more sensitive\n",
    "    threshold_high: 0.666 # below values make scar removal more sensitive\n",
    "    max_scar_width: 4 # Maximum thichness of scars in pixels.\n",
    "    min_scar_length: 16 # Minimum length of scars in pixels.\n",
    "...\n",
    "```\n",
    "\n",
    "For full details of all configuration options please refer to the [configuration](https://afm-spm.github.io/TopoStats/main/configuration.html)\n",
    "page of the official documentation.\n",
    "\n",
    "TopoStats comes with a `default_config.yaml` that is loaded by the cell below. This saves the options as a dictionary and\n",
    "we can access values by the keys. The example below prints out the top-levels keys and then the keys for the `filter`\n",
    "configuration. \n",
    "\n",
    "**NB** Python dictionaries have keys which can be considered as the parameter that is to be configured and each key has\n",
    "an associated value which is the value you wish to set the parameter to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ab1a0-888f-4631-92cd-4e026182b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from topostats.io import read_yaml\n",
    "\n",
    "config = read_yaml(\"data/default_config.yaml\")\n",
    "print(f\"Top level keys of config.yaml : \\n\\n {config.keys()}\\n\")\n",
    "print(f\"Configuration options for Filter : \\n\\n {config['filter'].keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fab4330-6408-46a7-b8b4-399e4f23d49d",
   "metadata": {},
   "source": [
    "Alternatively you can use the following button to upload your own configuration file. For convenience a copy of `default_config.yaml` is provided in the `data` directory of this Notebook that you can download and modify before uploading you changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49101750-d67b-4da8-9727-f0635b785da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO - How to load file into config?\n",
    "display(config_uploader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d65ca8b-6abe-48ef-8b01-c098fee42f2a",
   "metadata": {},
   "source": [
    "You can look at all of the options using the `json` package to \"pretty\" print the dictionary which makes it easier to\n",
    "read. Here we print the `filter` section. You can see the options map to those of the `Filter()` class with an\n",
    "additional `\"run\": true` which is used when running TopoStats at the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc7d226-1c55-4922-8629-8d011dceb36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(config[\"filter\"], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4244a01-43c9-440f-a497-27485806a65e",
   "metadata": {},
   "source": [
    "We will use the configuration options we have loaded in processing the `minicircle.spm` image. For convenience we save\n",
    "each set of options to their own dictionary and remove the `run` entry using the `.pop()` method as this is not required when running TopoStats in thos Notebook and would cause errors.\n",
    "\n",
    "We also set the `plotting_config[\"image_set\"]` to `all` so that all images can be plotted (there are some internal controls that determine whether images are plotted and returned).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef8e6f7-cee9-4e1e-a99d-7a431d8419bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_config = config[\"loading\"]\n",
    "filter_config = config[\"filter\"]\n",
    "filter_config.pop(\"run\")\n",
    "grain_config = config[\"grains\"]\n",
    "grain_config.pop(\"run\")\n",
    "grainstats_config = config[\"grainstats\"]\n",
    "grainstats_config.pop(\"run\")\n",
    "dnatracing_config = config[\"dnatracing\"]\n",
    "dnatracing_config.pop(\"run\")\n",
    "plotting_config = config[\"plotting\"]\n",
    "plotting_config.pop(\"run\")\n",
    "plotting_config[\"image_set\"] = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936bc985-0c5b-45ca-89bc-6937145c09d2",
   "metadata": {},
   "source": [
    "## Load Scans\n",
    "\n",
    "The first step before processing is to load a scan, this extracts the image data to a Numpy array along with the\n",
    "filepath and the pixel to nanometer scaling parameter which is used to correctly scale the pixels to images. These are\n",
    "stored in nested dictionaries with one top-level entry for each image that is found.\n",
    "\n",
    "One of the key fields you may wish to change is the `channel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3adfe6f-2d36-40eb-a9ef-71492c74d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scan_data = LoadScans(image_files, **config[\"loading\"])\n",
    "all_scan_data.get_data()\n",
    "\n",
    "# Plot the loaded scan in its raw format\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plt.imshow(all_scan_data.image, cmap=\"afmhot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a8b94-aaf0-4943-990c-801bd05aeb49",
   "metadata": {},
   "source": [
    "Now that we have loaded the data we can start to process it. The first step is filtering the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6cf4a8-771d-4176-9d4a-9133c5c35cad",
   "metadata": {},
   "source": [
    "## Filter Image\n",
    "\n",
    "Now that we have found some images the first step in processing is to filter them to remove some of the noise. This is\n",
    "achieved using the `Filters()` class.  There are a number of options that we need to specify which are described in the\n",
    "table below and also in the [documentation](https://topostats.readthedocs.io/en/dev/topostats.filters.html). \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Once we setup a `Filters` object we can call the different methods that are available for it. There are lots of\n",
    "different methods that carry out the different steps but for convenience the `filter_image()` method runs all these.\n",
    "\n",
    "The following section instantiates (\"sets up\") an object called `filtered_image` of type `Filters` using the first file\n",
    "found (`image_files[0]`) and the various options from the `filter_config` dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079d63e6-de86-47f9-afee-5cb85cef67e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from topostats.filters import Filters\n",
    "\n",
    "filtered_image = Filters(\n",
    "    image=all_scan_data.img_dict[\"minicircle\"][\"image_original\"],\n",
    "    filename=all_scan_data.img_dict[\"minicircle\"][\"img_path\"],\n",
    "    pixel_to_nm_scaling=all_scan_data.img_dict[\"minicircle\"][\"pixel_to_nm_scaling\"],\n",
    "    row_alignment_quantile=filter_config[\"row_alignment_quantile\"],\n",
    "    threshold_method=filter_config[\"threshold_method\"],\n",
    "    otsu_threshold_multiplier=filter_config[\"otsu_threshold_multiplier\"],\n",
    "    threshold_std_dev=filter_config[\"threshold_std_dev\"],\n",
    "    threshold_absolute=filter_config[\"threshold_absolute\"],\n",
    "    gaussian_size=filter_config[\"gaussian_size\"],\n",
    "    gaussian_mode=filter_config[\"gaussian_mode\"],\n",
    "    remove_scars=filter_config[\"remove_scars\"],\n",
    ")\n",
    "\n",
    "\n",
    "# NB - Because of the one-to-one mapping of configuration options to Filters() options we can use keyword arguments to\n",
    "#      unpack the options, the below is the same as explicitly stating the values you want to map.\n",
    "filtered_image = Filters(\n",
    "    image=all_scan_data.img_dict[\"minicircle\"][\"image_original\"],\n",
    "    filename=all_scan_data.img_dict[\"minicircle\"][\"img_path\"],\n",
    "    pixel_to_nm_scaling=all_scan_data.img_dict[\"minicircle\"][\"pixel_to_nm_scaling\"],\n",
    "    **filter_config,\n",
    ")\n",
    "filtered_image.filter_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e5ca8f-2e28-4ada-9209-6c3786abc9ec",
   "metadata": {},
   "source": [
    "The `filtered_image` now has a a number of NumPy arrays saved in the `.images` dictionary that can be accessed and plotted. To view\n",
    "the names of the images (technically the dictionary keys) you can print them with `filter_image.images.keys()`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b50fdf-befc-44af-906a-89c2facc6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Available NumPy arrays to plot in filter_image.images dictionary :\\n\\n{filtered_image.images.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0df4544-db43-410f-8e93-ba1f1038c9d1",
   "metadata": {},
   "source": [
    "To plot the raw extracted pixels you can use the built-in NumPy method `imshow()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ade9111-82ff-49cf-a653-114801461f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plt.imshow(filtered_image.images[\"gaussian_filtered\"], cmap=\"afmhot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d615afe-8b85-4a49-a309-6247077b8881",
   "metadata": {},
   "source": [
    "TopoStats includes a custom plotting class `Images`  which formats plots in a more familiar manner.\n",
    "\n",
    "It has a number of options, please refer to the official documentation on\n",
    "[configuration](https://afm-spm.github.io/TopoStats/configuration.html) under the `plotting` entry for what these values\n",
    "are or the [API\n",
    "reference](https://afm-spm.github.io/TopoStats/topostats.plottingfuncs.html#module-topostats.plottingfuncs).\n",
    "\n",
    "The class requires a Numpy array, which we have just generated many of during the various filtering stages, and a number\n",
    "of options. Again for convenience we use the `**plotting_config` notation to unpack the key/value pairs stored in the\n",
    "`plotting_config` dictionary.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37dc807-4422-4d33-8f18-6c4f228bf83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = Images(\n",
    "    data=filtered_image.images[\"gaussian_filtered\"],\n",
    "    filename=filtered_image.filename,\n",
    "    output_dir=\"img/\",\n",
    "    save=True,\n",
    "    **plotting_config,\n",
    ").plot_and_save()\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aec3b3-b6b7-464d-8f8f-bafe98b5d2bb",
   "metadata": {},
   "source": [
    "Here we plot the image after processing and zero-averaging the background but with the `viridis` palette and\n",
    "constraining the `zrange` to be between 0 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d32f5ef-b92e-4496-8f98-20739ff49eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO - Not getting fig, ax returned by plot_and_save()?\n",
    "# First remove the current value for cmap in the plotting_config dictionary, otherwise an error occurs because the same\n",
    "# argument will have been specified twice.\n",
    "current_cmap = plotting_config.pop(\"cmap\")\n",
    "current_zrange = plotting_config.pop(\"zrange\")\n",
    "fig, ax = Images(\n",
    "    data=filtered_image.images[\"gaussian_filtered\"],\n",
    "    filename=filtered_image.filename,\n",
    "    output_dir=\"img/\",\n",
    "    cmap=\"viridis\",\n",
    "    zrange=[0, 3],\n",
    "    save=True,\n",
    "    **plotting_config,\n",
    ").plot_and_save()\n",
    "# Restore the value for cmap to the dictionary.\n",
    "plotting_config[\"cmap\"] = current_cmap\n",
    "plotting_config[\"zrange\"] = current_zrange\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd4a5d0-9eef-42e4-9b3c-e9a30679d932",
   "metadata": {},
   "source": [
    "## Finding Grains\n",
    "\n",
    "The next step in processing the image is to find grains - a.k.a the molecules we want to analyse. This is done using the `Grains` class and we have saved the\n",
    "configuration to the `grains_config` dictionary. For details of the arguments and their values please refer to the\n",
    "[configuration](https://afm-spm.github.io/TopoStats/configuration.html) and the [API\n",
    "reference](https://afm-spm.github.io/TopoStats/topostats.grains.html).\n",
    "\n",
    "The most important thing required for grain finding is the resulting image from the Filtering stage, however several\n",
    "other key variables are required. Again there is a one-to-one mapping between the options to the `Grains()` class and\n",
    "their values in the configuration file.\n",
    "\n",
    "The `pixel_to_nm_scaling` is one of several key variables, as is the `filename` and whilst you can specify these\n",
    "yourself explicitly they are available as properties of the `filtered_image` that we have processed. As with `Filters`\n",
    "the `Grains` class has a number of methods that carry out the grain finding, but there is a convenience method\n",
    "`find_grains()` which calls all these in the correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f9c783-7862-4bd1-b5d7-0d8264589be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grains = Grains(\n",
    "    image=filtered_image.images[\"final_zero_average_background\"],\n",
    "    filename=filtered_image.filename,\n",
    "    pixel_to_nm_scaling=filtered_image.pixel_to_nm_scaling,\n",
    "    threshold_method=grain_config[\"threshold_method\"],\n",
    "    otsu_threshold_multiplier=grain_config[\"otsu_threshold_multiplier\"],\n",
    "    threshold_std_dev=grain_config[\"threshold_std_dev\"],\n",
    "    threshold_absolute=grain_config[\"threshold_absolute\"],\n",
    "    direction=grain_config[\"direction\"],\n",
    "    smallest_grain_size_nm2=grain_config[\"smallest_grain_size_nm2\"],\n",
    ")\n",
    "# NB - Again we can use the one-to-one mapping of configuration options in the grain_config we extracted.\n",
    "grains = Grains(\n",
    "    image=filtered_image.images[\"final_zero_average_background\"],\n",
    "    filename=filtered_image.filename,\n",
    "    pixel_to_nm_scaling=filtered_image.pixel_to_nm_scaling,\n",
    "    **grain_config,\n",
    ")\n",
    "grains.find_grains()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eeb5d238-0315-4e02-8db8-ac49ee141447",
   "metadata": {},
   "source": [
    "The `grains` object now also contains a series of images that we can plot, however, because both `below` and\n",
    "`above` layers can be processed for grains these reside under the `grains.directions[\"above\"]` and `grains.directions[\"below\"]` dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877afd6c-e8aa-437a-8478-c57548faecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Available NumPy arrays to plot in grains.directions['above'] dictionary :\\n\\n{grains.directions['above'].keys()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980c59e-fcdd-44b6-9d7f-97cd84b9d953",
   "metadata": {},
   "source": [
    "And we can again use the `plot_and_save()` function to plot these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ca9811-bf58-4fa3-8015-5c6be61f969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO - Not getting fig, ax returned by plot_and_save()?\n",
    "plotting_config[\"colorbar\"] = False\n",
    "fig, ax = Images(\n",
    "    data=grains.directions[\"above\"][\"coloured_regions\"],\n",
    "    filename=filtered_image.filename,\n",
    "    output_dir=\"img/\",\n",
    "    save=True,\n",
    "    **plotting_config,\n",
    ").plot_and_save()\n",
    "fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16e29698-4bd1-44ad-bd3b-dbc6d3744e08",
   "metadata": {},
   "source": [
    "### Thresholds\n",
    "\n",
    "The thresholds can be used in different ways based on the `direction` you want to detect grains. Typically for molecular\n",
    "imaging where the DNA or protein is raised above the background you will want to look for objects above the surface, using the `above`\n",
    "threshold. However, when imaging silicon, you may be interested in objects below the surface, using the `below` threshold. For convenience it is\n",
    "possible to look for grains that are `both` above the `above` threshold and `below` than the below threshold.\n",
    "\n",
    "This is controlled using the `config[\"grains\"][\"direction\"]` configuration option which maps to the `Grains(direction=)`\n",
    "option and can take three values `below`, `above` or `both`.\n",
    "\n",
    "If you want to change the option you can update the `config[\"grains\"]` dictionary as we do below. You will see that now\n",
    "we are using `both` there is twice as much output as grains are detected above the reported above Threshold (0.8064)\n",
    "_and_ below the reported below Threshold (-0.5333).\n",
    "\n",
    "So far the thresholding method used has been `threshold_method=\"std_dev\"` defined in the configuration file we\n",
    "loaded. This calculates the mean and standard deviation of height across the whole image and then determines the\n",
    "threshold by scaling the standard deviation by a given factor (defined by `threshold_std_dev`) and adding it to the mean\n",
    "to give the `above` threshold and/or subtracting if from the mean to give the `below` threshold.\n",
    "\n",
    "An alternative method is to use the `threshold_method=\"absolute\"`, set the `direction=above` and explicitly state the\n",
    "`below` and `above` thresholds (although since we are only looking for objects above a given threshold only the `above`\n",
    "value will be used). If you wish to specify values for both they are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db1923c-97fb-4e08-b682-9b69d76345a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ToDO - What are sensible values for minicircle here?\n",
    "grain_config[\"threshold_method\"] = \"absolute\"\n",
    "grain_config[\"direction\"] = \"above\"\n",
    "grain_config[\"threshold_absolute\"][\"above\"] = 0.01  # Change just the above threshold\n",
    "grain_config[\"threshold_absolute\"][\"below\"] = -2.0  # Change just the below threshold\n",
    "grain_config[\"threshold_absolute\"] = {\n",
    "    \"below\": -2.0,\n",
    "    \"above\": 1.2,\n",
    "}  # Change both the below and above threshold\n",
    "grains_absolute = Grains(\n",
    "    image=filtered_image.images[\"final_zero_average_background\"],\n",
    "    filename=filtered_image.filename,\n",
    "    pixel_to_nm_scaling=filtered_image.pixel_to_nm_scaling,\n",
    "    **grain_config,\n",
    ")\n",
    "grains_absolute.find_grains()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8f2f83-f99c-4e9e-a6b2-4c2292cda3e9",
   "metadata": {},
   "source": [
    "This is important because you need to know where the resulting images are stored within the `Grains.direction`\n",
    "dictionary. This will have entries corresponding to the `direction` that grains have been searched for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fd8ac7-067c-4989-a41f-dfea8470f429",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Grains available in original 'grains' (std_dev, above) : {list(grains.directions.keys())}\")\n",
    "print(f\"Grains available in absolute (absolute, above)         : {list(grains_absolute.directions.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fee325-0ad2-48a7-a332-7974890994d6",
   "metadata": {},
   "source": [
    "Each `direction` dictionary is a series of NumPy arrays representing the cleaned images and these can be plotted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ea42bd-234a-4e62-af19-d9900c1680aa",
   "metadata": {},
   "source": [
    "## Grain Statistics\n",
    "\n",
    "Now that the grains have been found we can calculate statistics for each. This is done using the `GrainStats()`\n",
    "class. Again the configuration options from the YAML file map to those of the class and there is a convenience method\n",
    "`calculate_stats()` which will run all steps of grain finding. However, because the class is processing results that we\n",
    "have generated we have to explicitly pass in more values.\n",
    "\n",
    "For details of what the arguments are please refer to the [API\n",
    "reference](https://afm-spm.github.io/TopoStats/topostats.grainstats.html).\n",
    "\n",
    "The `GrainStats` class returns two objects, a Pandas `pd.DataFrame` of calculated statistics and a `list` of\n",
    "dictionaries containing the grain data to be plotted. We therefore instantiate (\"set-up\") the `grain_stats` dictionary\n",
    "to hold these results and unpack each to the keys `statistics` and `plots` respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1de4c2c-b6df-4c0a-b829-d70111d31693",
   "metadata": {},
   "outputs": [],
   "source": [
    "grainstats = GrainStats(\n",
    "    data=filtered_image.images[\"gaussian_filtered\"],\n",
    "    labelled_data=grains.directions[\"above\"][\"labelled_regions_02\"],\n",
    "    pixel_to_nanometre_scaling=filtered_image.pixel_to_nm_scaling,\n",
    "    direction=\"above\",\n",
    "    base_output_dir=\"grains\",\n",
    "    image_name=filtered_image.filename.stem,\n",
    "    **grainstats_config,\n",
    ")\n",
    "_temp = grainstats.calculate_stats()\n",
    "grain_stats = {\"statistics\": _temp[0], \"plots\": _temp[1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893a3891-dbb9-45e5-9c7a-a3ee7160744d",
   "metadata": {},
   "source": [
    "The `statistics` is a [Pandas\n",
    "DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html). We can print this out as\n",
    "shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a003a3-49ca-401c-9173-2c60ea56f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "grain_stats[\"statistics\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ebf89b-4e1e-4a8c-b1b7-bb9343f2c6ea",
   "metadata": {},
   "source": [
    "Further we can summarise the dataframe or a subset of varaibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee090ac5-6023-4fdd-835a-e58ee184316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grain_stats[\"statistics\"][[\"smallest_bounding_width\", \"aspect_ratio\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ce88ce-9382-45a4-af4e-924aa28d9540",
   "metadata": {},
   "source": [
    "### Plotting Individual Grains\n",
    "\n",
    "It is possible to plot the individual grains in the same way that whole images are plotted. These are now stored as the\n",
    "`grain_stats[\"plots\"]` dictionary. We can find out how many grains there are either by looking at the number of rows\n",
    "reported when the statistics Pandas Data Frame was printed above or its summary (from `.describe()`), which reports the\n",
    "`count`.\n",
    "\n",
    "We can then plot any of these using the number indexing of the list. We using\n",
    "[f-strings](https://realpython.com/python-f-strings/) as the value for the argument `filename` to fill in the images\n",
    "filename automatically and append the `_grain#` for the image number we are plotting, in this example `0`. Try plotting\n",
    "some other images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0dcaf3-9e9b-468d-8596-2e613fda874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = Images(\n",
    "    data=grain_stats[\"plots\"][0][\"data\"],\n",
    "    filename=f\"{filtered_image.filename}_grain0\",\n",
    "    output_dir=\"img/\",\n",
    "    save=True,\n",
    "    **plotting_config,\n",
    ").plot_and_save()\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38127f7-9a6f-4970-b60e-0db2087e848f",
   "metadata": {},
   "source": [
    "## DNA Tracing\n",
    "\n",
    "When working with molecules it is possible to calculate DNA Tracing Statistics using the `dnatracing.py`'s `trace_image` function which takes an image and grain masks, and returns statistics about the dna.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777e48e3-908c-46a9-8795-c9ca13234609",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracing_results = trace_image(\n",
    "    image=filtered_image.images[\"gaussian_filtered\"],\n",
    "    grains_mask=grains.directions[\"above\"][\"labelled_regions_02\"],\n",
    "    filename=grains.filename.stem,\n",
    "    pixel_to_nm_scaling=grains.pixel_to_nm_scaling,\n",
    "    **dnatracing_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e14df4-54a5-4e4b-807a-cdefd4563aa4",
   "metadata": {},
   "source": [
    "The results are a dictionary, and the statistics are stored under the `\"statistics\"` key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec57f0f5-24a3-419d-9f49-a29749124767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at just the tracing stats\n",
    "tracing_stats = tracing_results[\"statistics\"]\n",
    "print(tracing_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7811717b-aa0e-4c03-b4b5-74223849b062",
   "metadata": {},
   "source": [
    "### Merge GrainStats and TracingStats\n",
    "\n",
    "Its reasonable to want to have a single data set with which we work and so we now merge the GrainStats data frame with\n",
    "the Tracing Statistics and then save them to CSV for subsequent use. The following saves them to the directory in which\n",
    "the Notebook is running with the filename `minicircle_example.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00804e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats_df = grain_stats[\"statistics\"].merge(tracing_stats, on=[\"image\", \"molecule_number\"])\n",
    "all_stats_df.to_csv(\"minicircle_example.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fe3e9d-45c9-4171-92d1-699a72888b5a",
   "metadata": {},
   "source": [
    "These statistics can now be plotted to show the distribution of the different metrics. Please see the Jupyter Notebook\n",
    "`notebooks/02-Summary-statistics-and-plots.ipynb` for examples of how to plot these statistics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "name": "00-Walkthrough-minicircle.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
